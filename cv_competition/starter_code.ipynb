{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from skimage import transform\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import numpy as np;\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random;\n",
    "import math;\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Vision Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This computer vision competition is on something called \"novelty detection\", which is where the goal is being able to learn to detect novelties. In other words, you are given a training set of data, $D_{train}$, and at test time you are given $D_{test}$ which contains both data types from $D_{train}$ as well as novel data that has not been seen before. The task is that, at test time, your model will need to classify an image as a type from $D_{train}$, or something novel. This is a twist on the classification problems we have gone over in this class.\n",
    "\n",
    "For this problem, we will be using the Fashion MNIST dataset as the training data. More information about this dataset can be found here: https://github.com/zalandoresearch/fashion-mnist \n",
    "\n",
    "At test time, we will run the model you have trained on a mystery dataset that is a combination of new Fashion MNIST data and also novel data from a different dataset, and your model will be ranked by how well it is able to distinguish Fashion data from novel data.\n",
    "\n",
    "Your model can output something like a probability (hint: use Sigmoid activation function at the end) or threshold cutoff that allows you to distinguish that an image is novel, and this will be used to perform a binary classification of sorts (either novel, or not novel). **The important thing is that at the very end, your model outputs either a 0 if you think the image is of the same type as the training data, and a 1 if your model thinks it is novel**. The highest accuracy of novelty detection will win this competition. There is a lot of creativity allowed in this project, so we recommend you brainstorm some new ideas or even read up on some novelty detection literature if you are interested. All code submitted must be your own.\n",
    "\n",
    "There is some skeleton code given, but feel free to change as much or as little as you would like, as long as you train using **only** the FashionMNIST dataset. Here are a couple of ideas on how you could go about this to get you started:\n",
    "\n",
    "* Traditional image classification assigns a probability of each label to an image, perhaps do something along the lines of thresholding so that if the highest probability an image has of being a certain label is still below $x$, it is novel\n",
    "* Checking how close/far a test image is to the training images, and thresholding\n",
    "* Looking at how close certain features (for example, 2 layers into a 4 layer CNN) may be to the training data\n",
    "\n",
    "At the end of training, be sure to save your model weights (code has been provided to do so). We will test your model, and the following is what you will need to submit (please include all of the code in the provided turnin.py file):\n",
    "\n",
    "* Code that includes\n",
    "    * Model architecture\n",
    "    * Preprocessing of images (must only use a variation of the given transform function)\n",
    "    * (Optional) postprocessing, instructions on this are in the last cell\n",
    "* Model weights in the form of a 'pth' file\n",
    "* Brief writeup giving a high-level overview of what you implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to change how much or little preprocessing is done, and at test \n",
    "# time the same preprocessing will be done on the test data\n",
    "# transform = transforms.Compose([\n",
    "# transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transform, target_transform=None, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  \n",
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ff4d875952ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Sample model\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1,out_channels=16,kernel_size=5,stride=1,padding=2)\n",
    "        self.relu1=nn.ELU()\n",
    "        nn.init.xavier_uniform(self.cnn1.weight)\n",
    "        self.maxpool1=nn.MaxPool2d(kernel_size=2)\n",
    "        self.cnn2=nn.Conv2d(in_channels=16,out_channels=32,kernel_size=5,stride=1,padding=2)\n",
    "        self.relu2=nn.ELU()\n",
    "        nn.init.xavier_uniform(self.cnn2.weight)\n",
    "        self.maxpool2=nn.MaxPool2d(kernel_size=2)\n",
    "#         self.cnn3 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=5,stride=1,padding=2)\n",
    "#         self.relu3=nn.ELU()      \n",
    "#         nn.init.xavier_uniform(self.cnn3.weight)\n",
    "#         self.maxpool3=nn.MaxPool2d(kernel_size=2)\n",
    "#         self.cnn4 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=5,stride=1,padding=2)\n",
    "#         self.relu4=nn.ELU()\n",
    "#         nn.init.xavier_uniform(self.cnn4.weight)\n",
    "#         self.maxpool4=nn.MaxPool2d(kernel_size=2)\n",
    "        self.fcl=nn.Linear(32*7*7,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out=self.cnn1(x)\n",
    "        out=self.relu1(out)\n",
    "        out=self.maxpool1(out)\n",
    "        out=self.cnn2(out)\n",
    "        out=self.relu2(out)\n",
    "        out=self.maxpool2(out)\n",
    "#         out=self.cnn3(out)\n",
    "#         out=self.relu3(out)\n",
    "#         out=self.maxpool3(out)\n",
    "#         out=self.cnn4(out)\n",
    "#         out=self.relu4(out)\n",
    "#         out=self.maxpool4(out)`\n",
    "        out=out.view(out.size(0),-1)\n",
    "        out=self.fcl(out)\n",
    "        batch = list(x.size())[0]\n",
    "        return out\n",
    "\n",
    "\n",
    "net = Net()\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample hyperparameters\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample loss functions and optimizers\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "learning_rate=0.015# BCELoss if output is sigmoid is recommended\n",
    "optimizer=torch.optim.SGD(net.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bf0076050ae5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-ff4d875952ce>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "number = len(train_loader)\n",
    "for epoch in range(epochs): \n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        outputs = outputs.squeeze().float()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i == (number - 10):\n",
    "            loss = running_loss / (number - 10)\n",
    "            print(\"Epoch: {0}, Loss: {1}\".format(epoch + 1, loss))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "directory = './saved_model/'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "torch.save(net.state_dict(), './saved_model/model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure your code is written in a way that is compatible with our testing framework, please make sure that the following code below runs. It also has the benefit of showing you how well your model does at classifying images from the training distribution correctly. It does **not** contain any of the novel images your model will eventually be tested on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that code works\n",
    "\n",
    "directory = './saved_model/'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "torch.save(net.state_dict(), './saved_model/model.pth')\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load('./saved_model/model.pth'))\n",
    "net.eval()\n",
    "f= open(\"result.txt\",\"w+\")\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transform, target_transform=None, download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "corrects = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for j, loader in enumerate([test_loader]):\n",
    "        for i, data in enumerate(loader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs=Variable(inputs)\n",
    "            outputs=net(inputs)\n",
    "            _,predicted=torch.max(outputs.data,1)\n",
    "            sm = torch.nn.Softmax() \n",
    "            probabilities = sm(outputs)\n",
    "            thresh = 0.7\n",
    "            for k in probabilities:\n",
    "                k = torch.max(k)\n",
    "                total += 1\n",
    "                if k >= thresh:\n",
    "                    k = 0\n",
    "                    print(k)\n",
    "                    f.write(str(k))\n",
    "                    if i < sub_lim:\n",
    "                        corrects += 1\n",
    "                else:\n",
    "                    k = 1\n",
    "                    print(k)\n",
    "                    f.write(str(k))\n",
    "                    if i > sub_lim:\n",
    "                        corrects += 1\n",
    "            #Converted to probabilities\n",
    "            # get the inputs\n",
    "            # If needed, can add a line here that thresholds, or does something with the\n",
    "            # 'outputs' variable to get it into a compatible format. An example is something\n",
    "            # like _, outputs = torch.max(outputs.data, 1). If this line is needed, please\n",
    "            # this along with your model architecture code labeled as 'postprocess'\n",
    "#             corrects[j] += (predicted==labels).sum()\n",
    "#             totals[j] += (labels.size(0))\n",
    "            \n",
    "f.close() \n",
    "accs = corrects / total\n",
    "print(\"Accuracy for test in distribution data:\", accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
